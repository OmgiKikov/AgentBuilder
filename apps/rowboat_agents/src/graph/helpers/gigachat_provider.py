from __future__ import annotations

from langchain_community.chat_models.gigachat import GigaChat
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import os
import json
import requests
import uuid
import urllib3
import re
import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from collections.abc import AsyncIterator

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ agents SDK
from agents.models.interface import Model, ModelTracing
from agents.items import ModelResponse, TResponseInputItem, TResponseStreamEvent
from agents.usage import Usage
from agents.tool import Tool
from agents.handoffs import Handoff
from agents.agent_output import AgentOutputSchemaBase
from agents.exceptions import AgentsException
from agents.models.chatcmpl_converter import Converter

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è output items
from openai.types.responses import (
    ResponseOutputMessage,
    ResponseOutputText,
    ResponseFunctionToolCall,
    ResponseCreatedEvent,
    ResponseOutputItemAddedEvent,
    ResponseContentPartAddedEvent, 
    ResponseTextDeltaEvent,
    ResponseContentPartDoneEvent,
    ResponseOutputItemDoneEvent,
    ResponseCompletedEvent,
    ResponseFunctionCallArgumentsDeltaEvent,
    Response,
    ResponseUsage
)
from openai.types.responses.response_usage import InputTokensDetails, OutputTokensDetails
from agents.models.fake_id import FAKE_RESPONSES_ID

# –î–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from agents.model_settings import ModelSettings

# –û—Ç–∫–ª—é—á–∞–µ–º SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# –ò–º–ø–æ—Ä—Ç –¥–ª—è MCP –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
try:
    from ..execute_turn_giga import call_mcp
except ImportError:
    # Fallback –µ—Å–ª–∏ –∏–º–ø–æ—Ä—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    async def call_mcp(tool_name: str, args: str, mcp_server_url: str) -> str:
        return f"MCP call to {tool_name} with args {args} (fallback implementation)"


@dataclass
class GigaChatUsage:
    total_tokens: int = 0
    input_tokens: int = 0
    output_tokens: int = 0


@dataclass
class GigaChatResponse:
    content: str
    usage: GigaChatUsage


def get_access_token(oauth_url="https://ngw.devices.sberbank.ru:9443/api/v2/oauth"):
    """–ü–æ–ª—É—á–∞–µ—Ç access token –¥–ª—è GigaChat API."""
    try:
        headers = {
            'Authorization': f"Bearer ZDFhY2IzYmMtNDU5OC00OThiLWFmM2UtZDg4MmU0Mjg3MTAzOjQxZDdkNTFkLTZiMzItNDU4MC05MjNhLTQ4MDgxZGZmYTBhOA==",
            'RqUID': str(uuid.uuid1()),
            'Content-Type': 'application/x-www-form-urlencoded',
        }
        
        data = {
            'scope': "GIGACHAT_API_CORP",
        }
        
        print(f"–ü–æ–ª—É—á–∞–µ–º access token –¥–ª—è GigaChat...")
        response = requests.post(oauth_url, headers=headers, data=data, verify=False)
        
        if response.status_code != 200:
            print(f"–û—à–∏–±–∫–∞ HTTP: {response.status_code}")
            print(f"–¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞: {response.text}")
            return None
            
        try:
            response_data = response.json()
        except ValueError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return None
            
        if 'access_token' not in response_data:
            print("–û—à–∏–±–∫–∞: access_token –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            return None
            
        access_token = response_data['access_token']
        print("‚úÖ Access token —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω!")
        return access_token
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞: {e}")
        return None


def init_gigachat_environment():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è GigaChat."""
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–µ–¥—ã GigaChat...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
    token = get_access_token()
    if not token:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å access token")
    
    os.environ["ACCESS_TOKEN"] = token
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º URL –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
    if not os.getenv("AIGATEWAY_URL"):
        os.environ["AIGATEWAY_URL"] = "https://gigachat.devices.sberbank.ru/api/v1"
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    try:
        url = os.getenv("AIGATEWAY_URL") + "/models"
        res = requests.get(
            url, 
            headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"}, 
            verify=False
        ).json()
        
        models_list = []
        models = res["data"]
        for model in models:
            models_list.append(model["id"])
        
        print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {models_list}")
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: 2-Max -> 2-Pro -> Pro -> Plus -> –æ–±—ã—á–Ω—ã–π)
        if "GigaChat-2-Max" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-2-Max"
        elif "GigaChat-2-Pro" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-2-Pro"
        elif "GigaChat-Pro" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-Pro"
        elif "GigaChat-Max" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-Max"
        elif "GigaChat-Plus" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-Plus"
        elif "GigaChat-2" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-2"
        elif "GigaChat" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat"
        else:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å")
        
        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {os.environ['GIGA_MODEL']}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º GigaChat –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {e}")
        os.environ["GIGA_MODEL"] = "GigaChat"


class GigaChatModel(Model):
    """GigaChat model implementation for the agents framework with tool calling support."""
    
    def __init__(self, credentials: str | None = None, auto_init: bool = True):
        if auto_init:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–µ–¥—É
            init_gigachat_environment()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
        self.access_token = credentials or os.getenv("ACCESS_TOKEN")
        if not self.access_token:
            raise ValueError("GigaChat credentials are required. Set ACCESS_TOKEN env var or pass credentials parameter.")
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏ URL
        self.model_name = os.getenv("GIGA_MODEL", "GigaChat")
        self.base_url = os.getenv("AIGATEWAY_URL", "https://gigachat.devices.sberbank.ru/api/v1")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç GigaChat
        self.client = GigaChat(
            verify_ssl_certs=False,
            model=self.model_name,
            access_token=self.access_token,
            profanity_check=False
        )
        
        print(f"‚úÖ GigaChatModel –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {self.model_name}")
    
    def _format_tools_for_gigachat(self, tools: list[Tool]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç GigaChat."""
        if not tools:
            return ""
        
        tools_prompt = "\n\n# –í–ê–ñ–ù–û: –£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã!\n\n"
        
        for tool in tools:
            tools_prompt += f"**{tool.name}**: {tool.description}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            if hasattr(tool, 'params_json_schema') and tool.params_json_schema:
                schema = tool.params_json_schema
                if 'properties' in schema:
                    tools_prompt += "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n"
                    for param_name, param_info in schema['properties'].items():
                        param_type = param_info.get('type', 'string')
                        param_desc = param_info.get('description', '')
                        required = param_name in schema.get('required', [])
                        req_text = " (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)" if required else " (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π)"
                        tools_prompt += f"  - {param_name} ({param_type}){req_text}: {param_desc}\n"
            
            tools_prompt += "\n"
        
        tools_prompt += """## –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

–ö–û–ì–î–ê –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–ª–∏ –∫–æ–≥–¥–∞ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ, —Ç—ã –î–û–õ–ñ–ï–ù –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –¢–û–ß–ù–´–ô —Ñ–æ—Ä–º–∞—Ç:

**TOOL_CALL_START**
tool_name: –Ω–∞–∑–≤–∞–Ω–∏–µ_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
parameters: {{"–ø–∞—Ä–∞–º–µ—Ç—Ä1": "–∑–Ω–∞—á–µ–Ω–∏–µ1", "–ø–∞—Ä–∞–º–µ—Ç—Ä2": "–∑–Ω–∞—á–µ–Ω–∏–µ2"}}
**TOOL_CALL_END**

–ü–†–ò–ú–ï–†–´:

–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç "–ò—Å–ø–æ–ª—å–∑—É–π greeting_tool":
**TOOL_CALL_START**
tool_name: greeting_tool
parameters: {{}}
**TOOL_CALL_END**

–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç "–í—ã—á–∏—Å–ª–∏ 10+5":
**TOOL_CALL_START**
tool_name: calculator_tool
parameters: {{"expression": "10+5"}}
**TOOL_CALL_END**

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û —ç—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç —Å **TOOL_CALL_START** –∏ **TOOL_CALL_END**
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç –º–µ–∂–¥—É –º–∞—Ä–∫–µ—Ä–∞–º–∏
- –ù–ï –æ—Ç–≤–µ—á–∞–π –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
- –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –∏—Ö –ø—Ä–æ—Å–∏—Ç
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ

"""
        return tools_prompt
    
    def _parse_tool_calls_from_response(self, response_content: str, tools: list[Tool]) -> tuple[str, list[dict]]:
        """–ü–∞—Ä—Å–∏—Ç tool calls –∏–∑ –æ—Ç–≤–µ—Ç–∞ GigaChat –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç + —Å–ø–∏—Å–æ–∫ –≤—ã–∑–æ–≤–æ–≤."""
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ tool calls
        tool_call_pattern = r'\*\*TOOL_CALL_START\*\*(.*?)\*\*TOOL_CALL_END\*\*'
        tool_calls_found = re.findall(tool_call_pattern, response_content, re.DOTALL)
        
        tool_calls_data = []
        
        for tool_call_text in tool_calls_found:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º tool_name
            tool_name_match = re.search(r'tool_name:\s*(\w+)', tool_call_text)
            if not tool_name_match:
                continue
            
            tool_name = tool_name_match.group(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–∞–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            tool_exists = any(tool.name == tool_name for tool in tools)
            if not tool_exists:
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º parameters
            params_match = re.search(r'parameters:\s*({.*?})', tool_call_text, re.DOTALL)
            if params_match:
                try:
                    parameters = json.loads(params_match.group(1))
                except json.JSONDecodeError:
                    parameters = {}
            else:
                parameters = {}
            
            tool_calls_data.append({
                'name': tool_name,
                'arguments': parameters,
                'id': f"call_{uuid.uuid4().hex[:8]}"
            })
        
        # –£–¥–∞–ª—è–µ–º tool calls –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞
        cleaned_response = re.sub(tool_call_pattern, '', response_content, flags=re.DOTALL)
        cleaned_response = cleaned_response.strip()
        
        return cleaned_response, tool_calls_data
    
    async def _execute_tool_call(self, tool_call: dict, tools: list[Tool]) -> str:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
        tool_name = tool_call['name']
        arguments = tool_call['arguments']
        
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        tool = next((t for t in tools if t.name == tool_name), None)
        if not tool:
            return f"–û—à–∏–±–∫–∞: –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {tool_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
            if hasattr(tool, 'on_invoke_tool') and tool.on_invoke_tool:
                # –°–æ–∑–¥–∞–µ–º mock context
                class MockContext:
                    pass
                
                ctx = MockContext()
                result = await tool.on_invoke_tool(ctx, arguments)
                return str(result)
            else:
                return f"–û—à–∏–±–∫–∞: –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {tool_name} –Ω–µ –∏–º–µ–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏"
                
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ {tool_name}: {str(e)}"
    
    async def get_response(
        self,
        system_instructions: str | None,
        input: str | list[TResponseInputItem],
        model_settings: ModelSettings,
        tools: list[Tool],
        output_schema: AgentOutputSchemaBase | None,
        handoffs: list[Handoff],
        tracing: ModelTracing,
        *,
        previous_response_id: str | None,
    ) -> ModelResponse:
        """Get a response from GigaChat model with tool calling support."""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt, user_message = self._convert_input_to_prompts(system_instructions, input)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if tools:
            tools_prompt = self._format_tools_for_gigachat(tools)
            system_prompt = system_prompt + tools_prompt
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ GigaChat
        try:
            response_content = self._chat_with_gigachat(system_prompt, user_message)
            
            # –ü–∞—Ä—Å–∏–º tool calls –∏–∑ –æ—Ç–≤–µ—Ç–∞
            cleaned_response, tool_calls_data = self._parse_tool_calls_from_response(response_content, tools)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º tool calls –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            final_response_parts = []
            if cleaned_response.strip():
                final_response_parts.append(cleaned_response.strip())
            
            for tool_call in tool_calls_data:
                tool_result = await self._execute_tool_call(tool_call, tools)
                final_response_parts.append(f"\nüîß –†–µ–∑—É–ª—å—Ç–∞—Ç {tool_call['name']}: {tool_result}")
            
            final_response = "\n".join(final_response_parts)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ agents
            output_items = self._create_output_items(final_response)
            
            # –°–æ–∑–¥–∞–µ–º usage —Å –æ—Ü–µ–Ω–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            usage = Usage(
                requests=1,
                input_tokens=self._estimate_tokens(system_prompt + user_message),
                output_tokens=self._estimate_tokens(final_response),
                total_tokens=self._estimate_tokens(system_prompt + user_message + final_response),
            )
            
            return ModelResponse(
                output=output_items,
                usage=usage,
                response_id=None,
            )
            
        except Exception as e:
            raise AgentsException(f"GigaChat API error: {str(e)}")
    
    async def stream_response(
        self,
        system_instructions: str | None,
        input: str | list[TResponseInputItem],
        model_settings: ModelSettings,
        tools: list[Tool],
        output_schema: AgentOutputSchemaBase | None,
        handoffs: list[Handoff],
        tracing: ModelTracing,
        *,
        previous_response_id: str | None,
    ) -> AsyncIterator[TResponseStreamEvent]:
        """Stream a response from GigaChat model with proper tool calling events."""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt, user_message = self._convert_input_to_prompts(system_instructions, input)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if tools:
            tools_prompt = self._format_tools_for_gigachat(tools)
            system_prompt = system_prompt + tools_prompt
        
        import time
        sequence_number = 0
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç GigaChat
            response_content = self._chat_with_gigachat(system_prompt, user_message)
            
            # –ü–∞—Ä—Å–∏–º tool calls –∏–∑ –æ—Ç–≤–µ—Ç–∞
            cleaned_response, tool_calls_data = self._parse_tool_calls_from_response(response_content, tools)
            
            # 1. Response Created Event
            initial_response = Response(
                id=FAKE_RESPONSES_ID,
                created_at=time.time(),
                model="gigachat",
                object="response",
                output=[],
                tool_choice="auto",
                top_p=model_settings.top_p,
                temperature=model_settings.temperature,
                tools=[],
                parallel_tool_calls=False,
                reasoning=None,
            )
            
            yield ResponseCreatedEvent(
                response=initial_response,
                type="response.created",
                sequence_number=sequence_number
            )
            sequence_number += 1
            
            # 2. –ï—Å–ª–∏ –µ—Å—Ç—å tool calls, —ç–º—É–ª–∏—Ä—É–µ–º –∏—Ö –∫–∞–∫ OpenAI
            if tool_calls_data:
                for tool_call in tool_calls_data:
                    # –°–æ–∑–¥–∞–µ–º ResponseFunctionToolCall –æ–±—ä–µ–∫—Ç
                    function_tool_call = ResponseFunctionToolCall(
                        arguments=json.dumps(tool_call['arguments']),
                        call_id=tool_call['id'],
                        name=tool_call['name'],
                        type='function_call',
                        id=FAKE_RESPONSES_ID,
                        status=None
                    )
                    
                    # Output Item Added Event –¥–ª—è function call
                    yield ResponseOutputItemAddedEvent(
                        item=function_tool_call,
                        output_index=0,
                        type="response.output_item.added",
                        sequence_number=sequence_number
                    )
                    sequence_number += 1
                    
                    # Function Call Arguments Delta Event
                    yield ResponseFunctionCallArgumentsDeltaEvent(
                        delta=json.dumps(tool_call['arguments']),
                        item_id=FAKE_RESPONSES_ID,
                        output_index=0,
                        type="response.function_call_arguments.delta",
                        sequence_number=sequence_number
                    )
                    sequence_number += 1
                    
                    # Output Item Done Event –¥–ª—è function call
                    yield ResponseOutputItemDoneEvent(
                        item=function_tool_call,
                        output_index=0,
                        type="response.output_item.done",
                        sequence_number=sequence_number
                    )
                    sequence_number += 1
                
                # Response Completed Event –ø–æ—Å–ª–µ –≤—Å–µ—Ö tool calls
                completed_response = Response(
                    id=FAKE_RESPONSES_ID,
                    created_at=time.time(),
                    model="gigachat",
                    object="response",
                    output=[ResponseFunctionToolCall(
                        arguments=json.dumps(tc['arguments']),
                        call_id=tc['id'],
                        name=tc['name'],
                        type='function_call',
                        id=FAKE_RESPONSES_ID,
                        status=None
                    ) for tc in tool_calls_data],
                    tool_choice="auto",
                    top_p=model_settings.top_p,
                    temperature=model_settings.temperature,
                    tools=[],
                    parallel_tool_calls=False,
                    reasoning=None,
                    usage=ResponseUsage(
                        input_tokens=self._estimate_tokens(system_prompt + user_message),
                        output_tokens=10,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è tool calls
                        total_tokens=self._estimate_tokens(system_prompt + user_message) + 10,
                        input_tokens_details=InputTokensDetails(cached_tokens=0),
                        output_tokens_details=OutputTokensDetails(reasoning_tokens=0)
                    )
                )
                
                yield ResponseCompletedEvent(
                    response=completed_response,
                    type="response.completed",
                    sequence_number=sequence_number
                )
                sequence_number += 1
                
                # –ù–ï –≤—ã–ø–æ–ª–Ω—è–µ–º tool calls –∑–¥–µ—Å—å - –ø–æ–∑–≤–æ–ª—è–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫—É agents –¥–µ–ª–∞—Ç—å —ç—Ç–æ
                # –≠—Ç–æ —Å–æ–∑–¥–∞—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ function spans —á–µ—Ä–µ–∑ tracing
                return
            
            # 3. –ï—Å–ª–∏ –Ω–µ—Ç tool calls, —Å–æ–∑–¥–∞–µ–º –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Ç–µ–∫—Å—Ç–æ–º
            if cleaned_response.strip():
                # Output Item Added (–Ω–∞—á–∞–ª–æ —Å–æ–æ–±—â–µ–Ω–∏—è)
                assistant_item = ResponseOutputMessage(
                    id=FAKE_RESPONSES_ID,
                    content=[],
                    role="assistant",
                    type="message",
                    status="in_progress",
                )
                
                yield ResponseOutputItemAddedEvent(
                    item=assistant_item,
                    output_index=0,
                    type="response.output_item.added",
                    sequence_number=sequence_number
                )
                sequence_number += 1
                
                # Content Part Added (–Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
                text_part = ResponseOutputText(
                    text="",
                    type="output_text",
                    annotations=[],
                )
                
                yield ResponseContentPartAddedEvent(
                    content_index=0,
                    item_id=FAKE_RESPONSES_ID,
                    output_index=0,
                    part=text_part,
                    type="response.content_part.added",
                    sequence_number=sequence_number
                )
                sequence_number += 1
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –ø–æ –∫—É—Å–æ—á–∫–∞–º (–∏–º–∏—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥)
                words = cleaned_response.strip().split()
                current_text = ""
                
                for word in words:
                    delta = word + " "
                    current_text += delta
                    
                    yield ResponseTextDeltaEvent(
                        content_index=0,
                        delta=delta,
                        item_id=FAKE_RESPONSES_ID,
                        output_index=0,
                        type="response.output_text.delta",
                        sequence_number=sequence_number
                    )
                    sequence_number += 1
                
                # –û–±–Ω–æ–≤–ª—è–µ–º text_part —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
                text_part.text = cleaned_response.strip()
                
                # Content Part Done (–∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
                yield ResponseContentPartDoneEvent(
                    content_index=0,
                    item_id=FAKE_RESPONSES_ID,
                    output_index=0,
                    part=text_part,
                    type="response.content_part.done",
                    sequence_number=sequence_number
                )
                sequence_number += 1
                
                # Output Item Done (–∫–æ–Ω–µ—Ü —Å–æ–æ–±—â–µ–Ω–∏—è)
                final_assistant_item = ResponseOutputMessage(
                    id=FAKE_RESPONSES_ID,
                    content=[text_part],
                    role="assistant",
                    type="message",
                    status="completed",
                )
                
                yield ResponseOutputItemDoneEvent(
                    item=final_assistant_item,
                    output_index=0,
                    type="response.output_item.done",
                    sequence_number=sequence_number
                )
                sequence_number += 1
                
                # 4. Response Completed (—Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ)
                final_response = Response(
                    id=FAKE_RESPONSES_ID,
                    created_at=time.time(),
                    model="gigachat",
                    object="response",
                    output=[ResponseOutputMessage(
                        id=FAKE_RESPONSES_ID,
                        content=[ResponseOutputText(
                            text=cleaned_response.strip(),
                            type="output_text",
                            annotations=[]
                        )],
                        role="assistant",
                        type="message",
                        status="completed",
                    )],
                    tool_choice="auto",
                    top_p=model_settings.top_p,
                    temperature=model_settings.temperature,
                    tools=[],
                    parallel_tool_calls=False,
                    reasoning=None,
                    usage=ResponseUsage(
                        input_tokens=self._estimate_tokens(system_prompt + user_message),
                        output_tokens=self._estimate_tokens(cleaned_response),
                        total_tokens=self._estimate_tokens(system_prompt + user_message + cleaned_response),
                        input_tokens_details=InputTokensDetails(cached_tokens=0),
                        output_tokens_details=OutputTokensDetails(reasoning_tokens=0)
                    )
                )
                
                yield ResponseCompletedEvent(
                    response=final_response,
                    type="response.completed",
                    sequence_number=sequence_number
                )
            
        except Exception as e:
            raise AgentsException(f"GigaChat streaming error: {str(e)}")
    
    def _convert_input_to_prompts(
        self, 
        system_instructions: str | None, 
        input: str | list[TResponseInputItem]
    ) -> tuple[str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ system_prompt –∏ user_message."""
        
        system_prompt = system_instructions or ""
        user_messages = []
        assistant_messages = []
        
        if isinstance(input, str):
            user_messages.append(input)
        else:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º - –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ç–æ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏ (–∫–∞–∫ –≤ playground)?
            if all(isinstance(item, dict) and 'role' in item for item in input):
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                for item in input:
                    role = item.get('role', 'user')
                    content = item.get('content', '')
                    
                    if role == "system":
                        system_prompt += f"\n{content}"
                    elif role == "user":
                        user_messages.append(content)
                    elif role == "assistant":
                        assistant_messages.append(content)
            else:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –∏–∑ agents SDK –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                try:
                    converted_messages = Converter.items_to_messages(input)
                    
                    for msg in converted_messages:
                        if hasattr(msg, 'role') and hasattr(msg, 'content'):
                            role = msg.role
                            content = self._extract_text_content(msg.content)
                            
                            if role == "system":
                                system_prompt += f"\n{content}"
                            elif role == "user":
                                user_messages.append(content)
                            elif role == "assistant":
                                assistant_messages.append(content)
                            elif role == "developer":
                                system_prompt += f"\nDeveloper note: {content}"
                            elif role == "tool":
                                system_prompt += f"\nTool output: {content}"
                                
                except Exception as e:
                    # Fallback: –ø—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                    print(f"‚ö†Ô∏è –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –æ–±—Ä–∞–±–æ—Ç–∫—É")
                    
                    for item in input:
                        if hasattr(item, 'role') and hasattr(item, 'content'):
                            role = getattr(item, 'role', 'user')
                            content = self._extract_text_content(getattr(item, 'content', ''))
                            
                            if role == "system":
                                system_prompt += f"\n{content}"
                            elif role == "user":
                                user_messages.append(content)
                            elif role == "assistant":
                                assistant_messages.append(content)
                        elif isinstance(item, dict):
                            role = item.get('role', 'user')
                            content = item.get('content', '')
                            
                            if role == "system":
                                system_prompt += f"\n{content}"
                            elif role == "user":
                                user_messages.append(content)
                            elif role == "assistant":
                                assistant_messages.append(content)
                        else:
                            # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
                            user_messages.append(str(item))
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π user_message —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞
        conversation_parts = []
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ
        if not user_messages and not assistant_messages:
            return system_prompt.strip(), ""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π)
        if len(user_messages) > 1 or len(assistant_messages) > 0:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –¥–∏–∞–ª–æ–≥–∞
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–¥—É—Ç –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
            all_messages = []
            
            # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            # –û–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: user -> assistant -> user -> assistant -> ... -> user (–ø–æ—Å–ª–µ–¥–Ω–∏–π)
            min_length = min(len(user_messages), len(assistant_messages))
            
            for i in range(min_length):
                if i < len(user_messages):
                    all_messages.append(f"User: {user_messages[i]}")
                if i < len(assistant_messages):
                    all_messages.append(f"Assistant: {assistant_messages[i]}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            for i in range(min_length, len(user_messages)):
                all_messages.append(f"User: {user_messages[i]}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            for i in range(min_length, len(assistant_messages)):
                all_messages.append(f"Assistant: {assistant_messages[i]}")
                
            if len(all_messages) > 1:
                conversation_parts.append("Previous conversation:")
                conversation_parts.extend(all_messages[:-1])  # –í—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                conversation_parts.append("\nCurrent user message:")
                if all_messages:
                    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "User: " –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    last_msg = all_messages[-1]
                    if last_msg.startswith("User: "):
                        conversation_parts.append(last_msg[6:])  # –£–±–∏—Ä–∞–µ–º "User: "
                    else:
                        conversation_parts.append(last_msg)
            else:
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "User: " –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                msg = all_messages[0] if all_messages else ""
                if msg.startswith("User: "):
                    conversation_parts.append(msg[6:])
                else:
                    conversation_parts.append(msg)
        elif len(user_messages) == 1:
            conversation_parts.append(user_messages[0])
        else:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω—É–∂–Ω–æ —á—Ç–æ-—Ç–æ –≤–µ—Ä–Ω—É—Ç—å
            conversation_parts.append("Please continue the conversation.")
        
        final_user_message = "\n".join(conversation_parts)
        
        return system_prompt.strip(), final_user_message.strip()
    
    def _extract_text_content(self, content) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤."""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            text_parts = []
            for item in content:
                if hasattr(item, 'text'):
                    text_parts.append(item.text)
                elif isinstance(item, dict) and 'text' in item:
                    text_parts.append(item['text'])
            return " ".join(text_parts)
        else:
            return str(content)
    
    def _chat_with_gigachat(self, system_prompt: str, user_message: str, max_retries: int = 3) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ GigaChat —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
        
        messages = [
            ("system", system_prompt),
            ("user", user_message)
        ]
        
        chat_template = ChatPromptTemplate.from_messages(messages=messages)
        chain = chat_template | self.client | StrOutputParser()
        
        for attempt in range(max_retries):
            try:
                result = chain.invoke({})
                return result
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞, –ø–æ–≤—Ç–æ—Ä—è–µ–º...")
                    import time
                    time.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                else:
                    raise e
    
    def _create_output_items(self, content: str) -> list:
        """–°–æ–∑–¥–∞–µ—Ç output items –≤ —Ñ–æ—Ä–º–∞—Ç–µ agents SDK."""
        
        message_item = ResponseOutputMessage(
            id=FAKE_RESPONSES_ID,
            content=[
                ResponseOutputText(
                    text=content, 
                    type="output_text", 
                    annotations=[]
                )
            ],
            role="assistant",
            type="message",
            status="completed",
        )
        
        return [message_item]
    
    def _estimate_tokens(self, text: str) -> int:
        """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤."""
        if not text:
            return 0
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        return len(text) // 4


# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
class GigaChatProvider(GigaChatModel):
    """Deprecated: Use GigaChatModel instead."""
    
    def __init__(self):
        super().__init__()
        import warnings
        warnings.warn(
            "GigaChatProvider is deprecated. Use GigaChatModel instead.",
            DeprecationWarning,
            stacklevel=2
        )
    
    def create_chat_completion(self, messages: List[Dict[str, Any]], **kwargs) -> GigaChatResponse:
        """Legacy method for backward compatibility."""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º system –∏ user —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt = ""
        user_message = ""
        
        for msg in messages:
            if msg["role"] == "system":
                system_prompt += f"\n{msg['content']}"
            elif msg["role"] == "user":
                user_message += f"\n{msg['content']}"
            elif msg["role"] == "assistant":
                user_message += f"\nAssistant said: {msg['content']}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response_content = self._chat_with_gigachat(system_prompt.strip(), user_message.strip())
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞
        return GigaChatResponse(
            content=response_content,
            usage=GigaChatUsage(
                total_tokens=self._estimate_tokens(system_prompt + user_message + response_content),
                input_tokens=self._estimate_tokens(system_prompt + user_message),
                output_tokens=self._estimate_tokens(response_content)
            )
        )

    async def create_chat_completion_stream(self, messages: List[Dict[str, Any]], **kwargs):
        """Legacy streaming method - just yields the complete response."""
        response = self.create_chat_completion(messages, **kwargs)
        yield response 