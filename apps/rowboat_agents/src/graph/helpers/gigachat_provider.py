from __future__ import annotations

from langchain_community.chat_models.gigachat import GigaChat
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import os
import json
import requests
import uuid
import urllib3
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from collections.abc import AsyncIterator

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ agents SDK
from agents.models.interface import Model, ModelTracing
from agents.items import ModelResponse, TResponseInputItem, TResponseStreamEvent
from agents.usage import Usage
from agents.tool import Tool
from agents.handoffs import Handoff
from agents.agent_output import AgentOutputSchemaBase
from agents.exceptions import AgentsException
from agents.models.chatcmpl_converter import Converter

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è output items
from openai.types.responses import (
    ResponseOutputMessage,
    ResponseOutputText,
    ResponseFunctionToolCall,
)
from agents.models.fake_id import FAKE_RESPONSES_ID

# –î–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from agents.model_settings import ModelSettings

# –û—Ç–∫–ª—é—á–∞–µ–º SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


@dataclass
class GigaChatUsage:
    total_tokens: int = 0
    input_tokens: int = 0
    output_tokens: int = 0


@dataclass
class GigaChatResponse:
    content: str
    usage: GigaChatUsage


def get_access_token(oauth_url="https://ngw.devices.sberbank.ru:9443/api/v2/oauth"):
    """–ü–æ–ª—É—á–∞–µ—Ç access token –¥–ª—è GigaChat API."""
    try:
        headers = {
            'Authorization': f"Bearer ZDFhY2IzYmMtNDU5OC00OThiLWFmM2UtZDg4MmU0Mjg3MTAzOjQxZDdkNTFkLTZiMzItNDU4MC05MjNhLTQ4MDgxZGZmYTBhOA==",
            'RqUID': str(uuid.uuid1()),
            'Content-Type': 'application/x-www-form-urlencoded',
        }
        
        data = {
            'scope': "GIGACHAT_API_CORP",
        }
        
        print(f"–ü–æ–ª—É—á–∞–µ–º access token –¥–ª—è GigaChat...")
        response = requests.post(oauth_url, headers=headers, data=data, verify=False)
        
        if response.status_code != 200:
            print(f"–û—à–∏–±–∫–∞ HTTP: {response.status_code}")
            print(f"–¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞: {response.text}")
            return None
            
        try:
            response_data = response.json()
        except ValueError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return None
            
        if 'access_token' not in response_data:
            print("–û—à–∏–±–∫–∞: access_token –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            return None
            
        access_token = response_data['access_token']
        print("‚úÖ Access token —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω!")
        return access_token
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞: {e}")
        return None


def init_gigachat_environment():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è GigaChat."""
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–µ–¥—ã GigaChat...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
    token = get_access_token()
    if not token:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å access token")
    
    os.environ["ACCESS_TOKEN"] = token
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º URL –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
    if not os.getenv("AIGATEWAY_URL"):
        os.environ["AIGATEWAY_URL"] = "https://gigachat.devices.sberbank.ru/api/v1"
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    try:
        url = os.getenv("AIGATEWAY_URL") + "/models"
        res = requests.get(
            url, 
            headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"}, 
            verify=False
        ).json()
        
        models_list = []
        models = res["data"]
        for model in models:
            models_list.append(model["id"])
        
        print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {models_list}")
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: 2-Max -> 2-Pro -> Pro -> Plus -> –æ–±—ã—á–Ω—ã–π)
        if "GigaChat-2-Max" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-2-Max"
        elif "GigaChat-2-Pro" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-2-Pro"
        elif "GigaChat-Pro" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-Pro"
        elif "GigaChat-Max" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-Max"
        elif "GigaChat-Plus" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-Plus"
        elif "GigaChat-2" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat-2"
        elif "GigaChat" in models_list:
            os.environ["GIGA_MODEL"] = "GigaChat"
        else:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å")
        
        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {os.environ['GIGA_MODEL']}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º GigaChat –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {e}")
        os.environ["GIGA_MODEL"] = "GigaChat"


class GigaChatModel(Model):
    """GigaChat model implementation for the agents framework."""
    
    def __init__(self, credentials: str | None = None, auto_init: bool = True):
        if auto_init:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–µ–¥—É
            init_gigachat_environment()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
        self.access_token = credentials or os.getenv("ACCESS_TOKEN")
        if not self.access_token:
            raise ValueError("GigaChat credentials are required. Set ACCESS_TOKEN env var or pass credentials parameter.")
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏ URL
        self.model_name = os.getenv("GIGA_MODEL", "GigaChat")
        self.base_url = os.getenv("AIGATEWAY_URL", "https://gigachat.devices.sberbank.ru/api/v1")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç GigaChat
        self.client = GigaChat(
            verify_ssl_certs=False,
            model=self.model_name,
            access_token=self.access_token,
            profanity_check=False
        )
        
        print(f"‚úÖ GigaChatModel –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {self.model_name}")
    
    async def get_response(
        self,
        system_instructions: str | None,
        input: str | list[TResponseInputItem],
        model_settings: ModelSettings,
        tools: list[Tool],
        output_schema: AgentOutputSchemaBase | None,
        handoffs: list[Handoff],
        tracing: ModelTracing,
        *,
        previous_response_id: str | None,
    ) -> ModelResponse:
        """Get a response from GigaChat model."""
        
        # –û—Ç–∫–ª—é—á–∞–µ–º tracing –¥–ª—è GigaChat —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ OpenAI
        tracing._disabled = True
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt, user_message = self._convert_input_to_prompts(system_instructions, input)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ GigaChat
        try:
            response_content = self._chat_with_gigachat(system_prompt, user_message)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ agents
            output_items = self._create_output_items(response_content)
            
            # –°–æ–∑–¥–∞–µ–º usage —Å –æ—Ü–µ–Ω–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            usage = Usage(
                requests=1,
                input_tokens=self._estimate_tokens(system_prompt + user_message),
                output_tokens=self._estimate_tokens(response_content),
                total_tokens=self._estimate_tokens(system_prompt + user_message + response_content),
            )
            
            return ModelResponse(
                output=output_items,
                usage=usage,
                response_id=None,
            )
            
        except Exception as e:
            raise AgentsException(f"GigaChat API error: {str(e)}")
    
    async def stream_response(
        self,
        system_instructions: str | None,
        input: str | list[TResponseInputItem],
        model_settings: ModelSettings,
        tools: list[Tool],
        output_schema: AgentOutputSchemaBase | None,
        handoffs: list[Handoff],
        tracing: ModelTracing,
        *,
        previous_response_id: str | None,
    ) -> AsyncIterator[TResponseStreamEvent]:
        """Stream a response from GigaChat model."""
        
        # –û—Ç–∫–ª—é—á–∞–µ–º tracing –¥–ª—è GigaChat —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ OpenAI
        tracing._disabled = True
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
        model_response = await self.get_response(
            system_instructions,
            input,
            model_settings,
            tools,
            output_schema,
            handoffs,
            tracing,
            previous_response_id=previous_response_id,
        )
        
        # –≠–º—É–ª–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π —Å—Ç—Ä–∏–º–∞
        from openai.types.responses import (
            ResponseCreatedEvent,
            ResponseOutputItemAddedEvent,
            ResponseContentPartAddedEvent, 
            ResponseTextDeltaEvent,
            ResponseContentPartDoneEvent,
            ResponseOutputItemDoneEvent,
            ResponseCompletedEvent,
            ResponseOutputText,
            ResponseOutputMessage,
            Response,
            ResponseUsage
        )
        from openai.types.responses.response_usage import InputTokensDetails, OutputTokensDetails
        import time
        
        sequence_number = 0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
        response_text = ""
        if model_response.output and len(model_response.output) > 0:
            output_item = model_response.output[0]
            if hasattr(output_item, 'content') and output_item.content:
                for content_part in output_item.content:
                    if hasattr(content_part, 'text'):
                        response_text = content_part.text
                        break
        
        # 1. Response Created Event
        initial_response = Response(
            id=FAKE_RESPONSES_ID,
            created_at=time.time(),
            model="gigachat",
            object="response",
            output=[],
            tool_choice="auto",
            top_p=model_settings.top_p,
            temperature=model_settings.temperature,
            tools=[],
            parallel_tool_calls=False,
            reasoning=None,
        )
        
        yield ResponseCreatedEvent(
            response=initial_response,
            type="response.created",
            sequence_number=sequence_number
        )
        sequence_number += 1
        
        # 2. Output Item Added (–Ω–∞—á–∞–ª–æ —Å–æ–æ–±—â–µ–Ω–∏—è)
        assistant_item = ResponseOutputMessage(
            id=FAKE_RESPONSES_ID,
            content=[],
            role="assistant",
            type="message",
            status="in_progress",
        )
        
        yield ResponseOutputItemAddedEvent(
            item=assistant_item,
            output_index=0,
            type="response.output_item.added",
            sequence_number=sequence_number
        )
        sequence_number += 1
        
        # 3. Content Part Added (–Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
        text_part = ResponseOutputText(
            text="",
            type="output_text",
            annotations=[],
        )
        
        yield ResponseContentPartAddedEvent(
            content_index=0,
            item_id=FAKE_RESPONSES_ID,
            output_index=0,
            part=text_part,
            type="response.content_part.added",
            sequence_number=sequence_number
        )
        sequence_number += 1
        
        # 4. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –ø–æ –∫—É—Å–æ—á–∫–∞–º (–∏–º–∏—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥)
        if response_text:
            # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
            words = response_text.split()
            current_text = ""
            
            for word in words:
                delta = word + " "
                current_text += delta
                
                yield ResponseTextDeltaEvent(
                    content_index=0,
                    delta=delta,
                    item_id=FAKE_RESPONSES_ID,
                    output_index=0,
                    type="response.output_text.delta",
                    sequence_number=sequence_number
                )
                sequence_number += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º text_part —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
            text_part.text = response_text.strip()
        
        # 5. Content Part Done (–∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
        yield ResponseContentPartDoneEvent(
            content_index=0,
            item_id=FAKE_RESPONSES_ID,
            output_index=0,
            part=text_part,
            type="response.content_part.done",
            sequence_number=sequence_number
        )
        sequence_number += 1
        
        # 6. Output Item Done (–∫–æ–Ω–µ—Ü —Å–æ–æ–±—â–µ–Ω–∏—è)
        final_assistant_item = ResponseOutputMessage(
            id=FAKE_RESPONSES_ID,
            content=[text_part],
            role="assistant",
            type="message",
            status="completed",
        )
        
        yield ResponseOutputItemDoneEvent(
            item=final_assistant_item,
            output_index=0,
            type="response.output_item.done",
            sequence_number=sequence_number
        )
        sequence_number += 1
        
        # 7. Response Completed (—Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ)
        final_response = Response(
            id=FAKE_RESPONSES_ID,
            created_at=time.time(),
            model="gigachat",
            object="response",
            output=[final_assistant_item],
            tool_choice="auto",
            top_p=model_settings.top_p,
            temperature=model_settings.temperature,
            tools=[],
            parallel_tool_calls=False,
            reasoning=None,
            usage=ResponseUsage(
                input_tokens=model_response.usage.input_tokens,
                output_tokens=model_response.usage.output_tokens,
                total_tokens=model_response.usage.total_tokens,
                input_tokens_details=InputTokensDetails(cached_tokens=0),
                output_tokens_details=OutputTokensDetails(reasoning_tokens=0)
            )
        )
        
        yield ResponseCompletedEvent(
            response=final_response,
            type="response.completed",
            sequence_number=sequence_number
        )
    
    def _convert_input_to_prompts(
        self, 
        system_instructions: str | None, 
        input: str | list[TResponseInputItem]
    ) -> tuple[str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ system_prompt –∏ user_message."""
        
        system_prompt = system_instructions or ""
        user_messages = []
        assistant_messages = []
        
        if isinstance(input, str):
            user_messages.append(input)
        else:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º - –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ç–æ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏ (–∫–∞–∫ –≤ playground)?
            if all(isinstance(item, dict) and 'role' in item for item in input):
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                for item in input:
                    role = item.get('role', 'user')
                    content = item.get('content', '')
                    
                    if role == "system":
                        system_prompt += f"\n{content}"
                    elif role == "user":
                        user_messages.append(content)
                    elif role == "assistant":
                        assistant_messages.append(content)
            else:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –∏–∑ agents SDK –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                try:
                    converted_messages = Converter.items_to_messages(input)
                    
                    for msg in converted_messages:
                        if hasattr(msg, 'role') and hasattr(msg, 'content'):
                            role = msg.role
                            content = self._extract_text_content(msg.content)
                            
                            if role == "system":
                                system_prompt += f"\n{content}"
                            elif role == "user":
                                user_messages.append(content)
                            elif role == "assistant":
                                assistant_messages.append(content)
                            elif role == "developer":
                                system_prompt += f"\nDeveloper note: {content}"
                            elif role == "tool":
                                system_prompt += f"\nTool output: {content}"
                                
                except Exception as e:
                    # Fallback: –ø—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                    print(f"‚ö†Ô∏è –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –æ–±—Ä–∞–±–æ—Ç–∫—É")
                    
                    for item in input:
                        if hasattr(item, 'role') and hasattr(item, 'content'):
                            role = getattr(item, 'role', 'user')
                            content = self._extract_text_content(getattr(item, 'content', ''))
                            
                            if role == "system":
                                system_prompt += f"\n{content}"
                            elif role == "user":
                                user_messages.append(content)
                            elif role == "assistant":
                                assistant_messages.append(content)
                        elif isinstance(item, dict):
                            role = item.get('role', 'user')
                            content = item.get('content', '')
                            
                            if role == "system":
                                system_prompt += f"\n{content}"
                            elif role == "user":
                                user_messages.append(content)
                            elif role == "assistant":
                                assistant_messages.append(content)
                        else:
                            # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
                            user_messages.append(str(item))
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π user_message —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞
        conversation_parts = []
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ
        if not user_messages and not assistant_messages:
            return system_prompt.strip(), ""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π)
        if len(user_messages) > 1 or len(assistant_messages) > 0:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –¥–∏–∞–ª–æ–≥–∞
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–¥—É—Ç –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
            all_messages = []
            
            # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            # –û–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: user -> assistant -> user -> assistant -> ... -> user (–ø–æ—Å–ª–µ–¥–Ω–∏–π)
            min_length = min(len(user_messages), len(assistant_messages))
            
            for i in range(min_length):
                if i < len(user_messages):
                    all_messages.append(f"User: {user_messages[i]}")
                if i < len(assistant_messages):
                    all_messages.append(f"Assistant: {assistant_messages[i]}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            for i in range(min_length, len(user_messages)):
                all_messages.append(f"User: {user_messages[i]}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            for i in range(min_length, len(assistant_messages)):
                all_messages.append(f"Assistant: {assistant_messages[i]}")
                
            if len(all_messages) > 1:
                conversation_parts.append("Previous conversation:")
                conversation_parts.extend(all_messages[:-1])  # –í—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                conversation_parts.append("\nCurrent user message:")
                if all_messages:
                    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "User: " –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    last_msg = all_messages[-1]
                    if last_msg.startswith("User: "):
                        conversation_parts.append(last_msg[6:])  # –£–±–∏—Ä–∞–µ–º "User: "
                    else:
                        conversation_parts.append(last_msg)
            else:
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "User: " –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                msg = all_messages[0] if all_messages else ""
                if msg.startswith("User: "):
                    conversation_parts.append(msg[6:])
                else:
                    conversation_parts.append(msg)
        elif len(user_messages) == 1:
            conversation_parts.append(user_messages[0])
        else:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω—É–∂–Ω–æ —á—Ç–æ-—Ç–æ –≤–µ—Ä–Ω—É—Ç—å
            conversation_parts.append("Please continue the conversation.")
        
        final_user_message = "\n".join(conversation_parts)
        
        return system_prompt.strip(), final_user_message.strip()
    
    def _extract_text_content(self, content) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤."""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            text_parts = []
            for item in content:
                if hasattr(item, 'text'):
                    text_parts.append(item.text)
                elif isinstance(item, dict) and 'text' in item:
                    text_parts.append(item['text'])
            return " ".join(text_parts)
        else:
            return str(content)
    
    def _chat_with_gigachat(self, system_prompt: str, user_message: str, max_retries: int = 3) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ GigaChat —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
        
        messages = [
            ("system", system_prompt),
            ("user", user_message)
        ]
        
        chat_template = ChatPromptTemplate.from_messages(messages=messages)
        chain = chat_template | self.client | StrOutputParser()
        
        for attempt in range(max_retries):
            try:
                result = chain.invoke({})
                return result
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞, –ø–æ–≤—Ç–æ—Ä—è–µ–º...")
                    import time
                    time.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                else:
                    raise e
    
    def _create_output_items(self, content: str) -> list:
        """–°–æ–∑–¥–∞–µ—Ç output items –≤ —Ñ–æ—Ä–º–∞—Ç–µ agents SDK."""
        
        message_item = ResponseOutputMessage(
            id=FAKE_RESPONSES_ID,
            content=[
                ResponseOutputText(
                    text=content, 
                    type="output_text", 
                    annotations=[]
                )
            ],
            role="assistant",
            type="message",
            status="completed",
        )
        
        return [message_item]
    
    def _estimate_tokens(self, text: str) -> int:
        """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤."""
        if not text:
            return 0
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        return len(text) // 4


# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
class GigaChatProvider(GigaChatModel):
    """Deprecated: Use GigaChatModel instead."""
    
    def __init__(self):
        super().__init__()
        import warnings
        warnings.warn(
            "GigaChatProvider is deprecated. Use GigaChatModel instead.",
            DeprecationWarning,
            stacklevel=2
        )
    
    def create_chat_completion(self, messages: List[Dict[str, Any]], **kwargs) -> GigaChatResponse:
        """Legacy method for backward compatibility."""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º system –∏ user —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt = ""
        user_message = ""
        
        for msg in messages:
            if msg["role"] == "system":
                system_prompt += f"\n{msg['content']}"
            elif msg["role"] == "user":
                user_message += f"\n{msg['content']}"
            elif msg["role"] == "assistant":
                user_message += f"\nAssistant said: {msg['content']}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response_content = self._chat_with_gigachat(system_prompt.strip(), user_message.strip())
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞
        return GigaChatResponse(
            content=response_content,
            usage=GigaChatUsage(
                total_tokens=self._estimate_tokens(system_prompt + user_message + response_content),
                input_tokens=self._estimate_tokens(system_prompt + user_message),
                output_tokens=self._estimate_tokens(response_content)
            )
        )

    async def create_chat_completion_stream(self, messages: List[Dict[str, Any]], **kwargs):
        """Legacy streaming method - just yields the complete response."""
        response = self.create_chat_completion(messages, **kwargs)
        yield response 