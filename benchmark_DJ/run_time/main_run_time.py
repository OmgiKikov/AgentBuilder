#!/usr/bin/env python3
"""
–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–π
"""

import asyncio
import os
import json
import sys
from datetime import datetime, timezone
from bson import ObjectId

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å –ø–æ–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from apps.experimental.simulation_runner.db import get_collection
from apps.experimental.simulation_runner.service import JobService
from apps.experimental.simulation_runner.check_db import get_simulation_pairs

def json_serializer(obj):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è JSON"""
    if isinstance(obj, ObjectId):
        return str(obj)
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")

def create_test_run(project_id: str, workflow_id: str, simulation_id: str, simulation_name: str):
    """
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –¥–ª—è –æ–¥–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏
    """
    runs_collection = get_collection("test_runs")
    
    # –°–æ–∑–¥–∞–µ–º –ù–û–í–´–ô –∑–∞–ø—É—Å–∫
    run_id = str(ObjectId())
    test_run = {
        "_id": ObjectId(run_id),
        "projectId": project_id,
        "name": f"–ê–≤—Ç–æ—Ç–µ—Å—Ç: {simulation_name}",
        "simulationIds": [simulation_id],
        "workflowId": workflow_id,
        "status": "pending",
        "startedAt": datetime.now(timezone.utc),
        "completedAt": None,
        "aggregateResults": None,
        "lastHeartbeat": None
    }
    
    runs_collection.insert_one(test_run)
    return run_id

async def run_single_simulation(simulation_data: dict, workflow_id: str, max_dialog_iterations: int = 2):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–Ω—É —Å–∏–º—É–ª—è—Ü–∏—é
    """
    print("=" * 80)
    print(f"   –ó–ê–ü–£–°–ö –°–ò–ú–£–õ–Ø–¶–ò–ò: {simulation_data['name']}")
    print("=" * 80)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API
    os.environ["ROWBOAT_API_HOST"] = "http://127.0.0.1:3000"
    
    print(f"üè¢ –ü—Ä–æ–µ–∫—Ç: {simulation_data['project_id']}")
    print(f"‚ö° Workflow: {workflow_id}")
    print(f"üìã –°—Ü–µ–Ω–∞—Ä–∏–π: {simulation_data['scenario_id']}")
    print(f"üîÑ –°–∏–º—É–ª—è—Ü–∏—è: {simulation_data['simulation_id']}")
    print(f"üí¨ –ò—Ç–µ—Ä–∞—Ü–∏–π –¥–∏–∞–ª–æ–≥–∞: {max_dialog_iterations}")
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—É—Å–∫
    run_id = create_test_run(
        project_id=simulation_data['project_id'],
        workflow_id=workflow_id,
        simulation_id=simulation_data['simulation_id'],
        simulation_name=simulation_data['name']
    )
    print(f"‚ñ∂Ô∏è  –ó–∞–ø—É—Å–∫: {run_id} (—Å—Ç–∞—Ç—É—Å: pending)")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–∏—Å
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞...")
    service = JobService()
    
    try:
        await service.poll_and_process_jobs(max_iterations_pre_m=20, max_iterations=max_dialog_iterations, target_run_id=run_id)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    runs_collection = get_collection("test_runs")
    final_run = runs_collection.find_one({"_id": ObjectId(run_id)})
    
    results_collection = get_collection("test_results")
    test_results = list(results_collection.find({"runId": run_id}))
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏ '{simulation_data['name']}':")
    if final_run:
        print(f"   –°—Ç–∞—Ç—É—Å: {final_run['status']}")
        if final_run.get('aggregateResults'):
            results = final_run['aggregateResults']
            print(f"   –í—Å–µ–≥–æ: {results.get('total', 0)}")
            print(f"   –£—Å–ø–µ—à–Ω–æ: {results.get('passCount', 0)}")
            print(f"   –ù–µ—É–¥–∞—á–Ω–æ: {results.get('failCount', 0)}")
    
    last_result = None
    if test_results:
        for i, test_result in enumerate(test_results, 1):
            print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç {i}: {test_result.get('result', 'unknown')}")
            print(f"   –î–µ—Ç–∞–ª–∏: {test_result.get('details', '–Ω–µ—Ç –¥–µ—Ç–∞–ª–µ–π')[:100]}...")
            last_result = test_result
    else:
        print("   ‚ö†Ô∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    
    print()

    aggregate_results = final_run.get('aggregateResults') if final_run else None

    return {
        "simulation_name": simulation_data['name'],
        "run_id": run_id,
        "status": final_run['status'] if final_run else "unknown",
        "results_count": len(test_results),
        "result": last_result,
        "aggregate_results": aggregate_results
    }

def get_project_workflow_mapping():
    """
    –ü–æ–ª—É—á–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –ø—Ä–æ–µ–∫—Ç–æ–≤ –Ω–∞ –∏—Ö workflow ID –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    """
    workflows_collection = get_collection('agent_workflows')
    workflows = list(workflows_collection.find({}))
    
    project_workflow_map = {}
    for workflow in workflows:
        project_id = workflow.get('projectId')
        workflow_id = str(workflow['_id'])
        project_workflow_map[project_id] = workflow_id
    
    return project_workflow_map

async def run_simulation_task(simulation_data: dict, workflow_id: str, max_dialog_iterations: int, index: int, total: int):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–¥–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏."""
    print(f"üîÑ –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ {index}/{total}: {simulation_data['name']}")
    sim_start_time = datetime.now()
    result = await run_single_simulation(
        simulation_data=simulation_data,
        workflow_id=workflow_id,
        max_dialog_iterations=max_dialog_iterations
    )
    sim_end_time = datetime.now()
    latency = (sim_end_time - sim_start_time).total_seconds()

    if result:
        result["scenario_name"] = simulation_data["scenario_name"]
    
    return result, latency

async def run_batch_simulations(name_model):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–∏–º—É–ª—è—Ü–∏–∏ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û
    """
    print("=" * 80)
    print("   –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –°–ò–ú–£–õ–Ø–¶–ò–ô")
    print("=" * 80)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–∏–º—É–ª—è—Ü–∏–π —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ runtime.json
    simulation_pairs = get_simulation_pairs()
    
    if not simulation_pairs:
        print("‚ùå –°–∏–º—É–ª—è—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ —Å–∏–º—É–ª—è—Ü–∏–π: {len(simulation_pairs)}")
    
    # –û—á–∏—â–∞–µ–º –í–°–ï —Å—Ç–∞—Ä—ã–µ –∑–∞–ø—É—Å–∫–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    runs_collection = get_collection("test_runs")
    results_collection = get_collection("test_results")
    
    # –û—á–∏—â–∞–µ–º –≤—Å–µ –∑–∞–ø—É—Å–∫–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º pending –∏–ª–∏ running
    deleted_runs = runs_collection.delete_many({
        "$or": [
            {"status": "pending"},
            {"status": "running"},
            {"name": {"$regex": "^–ê–≤—Ç–æ—Ç–µ—Å—Ç:"}}
        ]
    })
    deleted_results = results_collection.delete_many({})
    print(f"\nüßπ –û—á–∏—â–µ–Ω–æ {deleted_runs.deleted_count} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤")
    print(f"üßπ –û—á–∏—â–µ–Ω–æ {deleted_results.deleted_count} —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print()
    
    # --- –ú–µ—Ç—Ä–∏–∫–∏ ---
    failed_simulations = 0
    latencies = []
    start_time = datetime.now()
    # ----------------

    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    tasks = []
    skipped_simulations = 0
    
    for i, simulation_data in enumerate(simulation_pairs, 1):
        project_id = simulation_data["project_id"]
        workflow_id = simulation_data.get("workflow_id")
        max_iterations = simulation_data.get("MAX_DIALOG_ITERATIONS", 1)
        
        if not workflow_id:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–µ–∫—Ç {project_id[:8]}... - workflow –Ω–µ –Ω–∞–π–¥–µ–Ω")
            skipped_simulations += 1
            continue
        
        tasks.append(run_simulation_task(simulation_data, workflow_id, max_iterations, i, len(simulation_pairs)))

    total_simulations_to_run = len(tasks)
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º {total_simulations_to_run} —Å–∏–º—É–ª—è—Ü–∏–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏ –∂–¥–µ–º –∏—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    all_results = await asyncio.gather(*tasks)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å–∏–º—É–ª—è—Ü–∏—é
    batch_results = []
    for result, latency in all_results:
        latencies.append(latency)
        if result:
            batch_results.append(result)
            if result["status"] != "completed" or (result.get("aggregate_results") and result["aggregate_results"].get("failCount", 0) > 0):
                failed_simulations += 1
        else:
            failed_simulations += 1

    # --- –†–∞—Å—á–µ—Ç –∏ –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ ---
    end_time = datetime.now()
    total_execution_time = (end_time - start_time).total_seconds()

    avg_latency = sum(latencies) / len(latencies) if latencies else 0
    throughput = total_simulations_to_run / total_execution_time if total_execution_time > 0 else 0
    error_rate = (failed_simulations / total_simulations_to_run) * 100 if total_simulations_to_run > 0 else 0

    print("=" * 80)
    print("   –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 80)
    print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_execution_time:.2f} —Å–µ–∫")
    print(f"‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (Latency): {avg_latency:.2f} —Å–µ–∫")
    print(f"üöÄ –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å (Throughput): {throughput:.2f} —Å–∏–º—É–ª—è—Ü–∏–π/—Å–µ–∫")
    print(f"üìâ –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ (Error Rate): {error_rate:.2f}%")
    print("=" * 80)
    # -----------------------------

    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("=" * 80)
    print("   –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 80)
    
    for result in batch_results:
        print(f"‚úÖ {result['simulation_name']}: {result['status']} ({result['results_count']} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)")
    
    total_processed = len(batch_results) + skipped_simulations
    print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏–º—É–ª—è—Ü–∏–π: {total_processed}/{len(simulation_pairs)}")

    for item in batch_results:
        try:
            transcript_str = item.get("result", {}).get("transcript")
            if transcript_str and isinstance(transcript_str, str):
                try:
                    item["result"]["transcript"] = json.loads(transcript_str)
                except json.JSONDecodeError:
                    # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON ‚Äî –º–æ–∂–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å
                    pass
        except:
            pass
    
    # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    safe_name_model = name_model.replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')
    
    with open(f"benchmark/run_time/run_time_result_{safe_name_model}.json", 'w', encoding='utf-8') as f:
        json.dump(batch_results, f, ensure_ascii=False, indent=4, default=json_serializer)

if __name__ == "__main__":
    name_model = "google/gemini-2.5-pro"
    asyncio.run(run_batch_simulations(name_model)) 